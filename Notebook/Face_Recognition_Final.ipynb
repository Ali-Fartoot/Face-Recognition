{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac056401",
   "metadata": {},
   "source": [
    "# Import files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7758654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import uuid\n",
    "import cv2\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, SubsetRandomSampler\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37eb94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join(\"..\",\"test\",'data','positive')\n",
    "NEG_PATH = os.path.join(\"..\",\"test\",'data','negetive')\n",
    "ANC_PATH = os.path.join(\"..\",\"test\",'data','anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3e518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fa975",
   "metadata": {},
   "source": [
    "# Wild Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4d7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Collect anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9573ec",
   "metadata": {},
   "source": [
    "# Data Augmention and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de16e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "def data_aug(img):\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    img = F.adjust_brightness(img, brightness_factor=1.05)\n",
    "    data.append(img)\n",
    "\n",
    "    img = F.adjust_contrast(img, contrast_factor=torch.empty(1).uniform_(0.6, 1).item())\n",
    "    data.append(img)\n",
    "            \n",
    "    img = F.hflip(img)\n",
    "    data.append(img)\n",
    "    \n",
    "    img = F.adjust_saturation(img, saturation_factor=torch.empty(1).uniform_(0.9, 1).item())\n",
    "    data.append(img)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ddfd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "files = os.listdir(os.path.join(POS_PATH))\n",
    "length = len(os.listdir(NEG_PATH)) - len(files)     \n",
    "\n",
    "while count < length:\n",
    "    for file_name in files:\n",
    "        img_path = os.path.join(POS_PATH, file_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = F.to_tensor(img)\n",
    "        augmented_images = data_aug(img_tensor)\n",
    "        for i, image in enumerate(augmented_images):\n",
    "            image = F.to_pil_image(image)\n",
    "            image.save(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())))\n",
    "        else:\n",
    "            count+=4\n",
    "            \n",
    "files = os.listdir(os.path.join(POS_PATH))            \n",
    "while len(os.listdir(NEG_PATH)) - len(files)  >0:\n",
    "    file_name = files[len(files) - 4]\n",
    "\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = F.to_tensor(img)\n",
    "    image.save(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())))\n",
    "    files = os.listdir(os.path.join(POS_PATH))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bb60e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "files = os.listdir(os.path.join(ANC_PATH))\n",
    "length = len(os.listdir(NEG_PATH)) - len(files)     \n",
    "\n",
    "while count < length:\n",
    "    for file_name in files:\n",
    "        img_path = os.path.join(ANC_PATH, file_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = F.to_tensor(img)\n",
    "        augmented_images = data_aug(img_tensor)\n",
    "        for i, image in enumerate(augmented_images):\n",
    "            image = F.to_pil_image(image)\n",
    "            image.save(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())))\n",
    "        else:\n",
    "            count+=4\n",
    "            \n",
    "files = os.listdir(os.path.join(ANC_PATH))            \n",
    "while len(os.listdir(NEG_PATH)) - len(files)  >0:\n",
    "    file_name = files[len(files) - 4]\n",
    "\n",
    "    img_path = os.path.join(ANC_PATH, file_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = F.to_tensor(img)\n",
    "    image.save(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())))\n",
    "    files = os.listdir(os.path.join(ANC_PATH))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bae2320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeImageDataset(Dataset):\n",
    "    def __init__(self,ANC_PATH  ,POS_PATH, NEG_PATH, types ,transform = None):\n",
    "        \n",
    "        self.POS_PATH = POS_PATH\n",
    "        self.NEG_PATH = NEG_PATH\n",
    "        self.ANC_PATH = ANC_PATH\n",
    "        \n",
    "        self.types = types\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.POS_IMG = os.listdir(POS_PATH)\n",
    "        self.NEG_IMG = os.listdir(NEG_PATH)\n",
    "        self.ANC_IMG = os.listdir(ANC_PATH)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ANC_IMG)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anc_dir  = os.path.join(self.ANC_PATH, self.ANC_IMG[idx])\n",
    "        anc_image = Image.open(anc_dir).convert('RGB')\n",
    "        \n",
    "        if self.types == 1: \n",
    "            pos_dir  = os.path.join(self.POS_PATH, self.POS_IMG[idx])\n",
    "            pos_image = Image.open(pos_dir).convert('RGB')\n",
    "\n",
    "        if self.types == 0: \n",
    "            neg_dir  = os.path.join(self.NEG_PATH, self.NEG_IMG[idx])\n",
    "            neg_image = Image.open(neg_dir).convert('RGB')\n",
    "        \n",
    "        data = [anc_image, pos_image if self.types == 1 else neg_image, torch.ones(1) if self.types == 1 else torch.zeros(1) ]\n",
    "\n",
    "        if self.transform:\n",
    "            data[0] = self.transform(data[0])\n",
    "            data[1] = self.transform(data[1])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b9701f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                transforms.ToTensor()])\n",
    "positive = MergeImageDataset(ANC_PATH, POS_PATH, NEG_PATH, types = 1, transform = transform)\n",
    "negtive = MergeImageDataset(ANC_PATH, POS_PATH, NEG_PATH, types = 0, transform = transform)\n",
    "data = ConcatDataset([negtive,positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c192fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "indices = list(range(num_samples))\n",
    "random.shuffle(indices)\n",
    "split = int(math.floor(0.4 * num_samples))  # Use 20% of data for validation\n",
    "print(split)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Create samplers for the training and validation parts\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = DataLoader(data, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(data, batch_size=32, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73615f27",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc403e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(Embedding, self).__init__()\n",
    "\n",
    "            self.conv_1 = nn.Conv2d(3, 64,kernel_size=(10, 10))\n",
    "            self.relu_1 = nn.ReLU()\n",
    "            self.maxpool_1 = nn.MaxPool2d(2, stride = 2 ,padding = 1)\n",
    "            \n",
    "            self.conv_2 =  nn.Conv2d(64, 128,kernel_size=(7, 7))\n",
    "            self.relu_2 =  nn.ReLU()\n",
    "            self.maxpool_2 = nn.MaxPool2d(2 , 2)\n",
    "            \n",
    "            self.conv_3 =  nn.Conv2d(128, 128,kernel_size=(4, 4))\n",
    "            self.relu_3 =  nn.ReLU()\n",
    "            self.maxpool_3 =  nn.MaxPool2d(2, 2, padding = 1)\n",
    "            \n",
    "            self.conv_4 =  nn.Conv2d(128, 256,kernel_size=(4, 4))\n",
    "            self.relu_4 =  nn.ReLU()\n",
    "            self.flatten = nn.Flatten(start_dim=1)\n",
    "            \n",
    "            self.normalization_64 =  nn.BatchNorm2d(64)\n",
    "            self.normalization_128 =  nn.BatchNorm2d(128)\n",
    "\n",
    "            self.linear = nn.Linear(256 * 6 * 6, 4096)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.normalization_64(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = self.normalization_128(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.maxpool_3(x)\n",
    "        x = self.normalization_128(x)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99ee853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.embeder = Embedding()\n",
    "        self.classifier = nn.Linear(4096,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_image, validation_image):\n",
    "        input_image = self.embeder(input_image)\n",
    "        validation_image = self.embeder(validation_image)\n",
    "        result = torch.abs(input_image - validation_image)\n",
    "        x = self.classifier(result)\n",
    "        x = self.sigmoid(x)\n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73754b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round(data):\n",
    "    for i, value in enumerate(data):\n",
    "        data[i] = 0 if value < 0.5 else 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "944800c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Epoch [1/10]\n",
      "Val Total Loss 1.973756 :\n",
      "Val Average Loss 0.001234 :\n",
      "Val Accuracy 98.94 :\n",
      "Epoch [2/10]\n",
      "Val Total Loss 0.762965 :\n",
      "Val Average Loss 0.000477 :\n",
      "Val Accuracy 99.56 :\n",
      "Epoch [3/10]\n",
      "Val Total Loss 0.477422 :\n",
      "Val Average Loss 0.000298 :\n",
      "Val Accuracy 99.75 :\n",
      "Epoch [4/10]\n",
      "Val Total Loss 0.618737 :\n",
      "Val Average Loss 0.000387 :\n",
      "Val Accuracy 99.62 :\n",
      "Epoch [5/10]\n",
      "Val Total Loss 0.443144 :\n",
      "Val Average Loss 0.000277 :\n",
      "Val Accuracy 99.69 :\n",
      "Epoch [6/10]\n",
      "Val Total Loss 0.451739 :\n",
      "Val Average Loss 0.000282 :\n",
      "Val Accuracy 99.75 :\n",
      "Epoch [7/10]\n",
      "Val Total Loss 0.544950 :\n",
      "Val Average Loss 0.000341 :\n",
      "Val Accuracy 99.75 :\n",
      "Epoch [8/10]\n",
      "Val Total Loss 0.527080 :\n",
      "Val Average Loss 0.000329 :\n",
      "Val Accuracy 99.75 :\n",
      "Epoch [9/10]\n",
      "Val Total Loss 0.502910 :\n",
      "Val Average Loss 0.000314 :\n",
      "Val Accuracy 99.75 :\n",
      "Epoch [10/10]\n",
      "Val Total Loss 0.515173 :\n",
      "Val Average Loss 0.000322 :\n",
      "Val Accuracy 99.75 :\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "torch.manual_seed(34)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create an instance of the SiameseNetwork\n",
    "siamese_net = SiameseNetwork().to(device)\n",
    "\n",
    "# Define the loss function (e.g., Binary Cross Entropy)\n",
    "criterion =  nn.BCELoss()\n",
    "\n",
    "# Define the optimizer (e.g., Stochastic Gradient Descent)\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "accuracies = []\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    total_samples = 0\n",
    "    # Iterate over the training dataset\n",
    "    for i, (input_image, validation_image, label) in enumerate(train_loader):     \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        input_image = input_image.to(device)\n",
    "        validation_image = validation_image.to(device)\n",
    "        label = label.to(device)\n",
    "        # Forward pass\n",
    "        output = siamese_net(input_image, validation_image)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the running loss\n",
    "        train_loss += loss.item()\n",
    "        total_samples += label.size(0)  # Increment total_samples by the batch size\n",
    "    \n",
    "    avg_train_loss = train_loss / total_samples\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    \n",
    "        # Evaluate the model on the validation set\n",
    "\n",
    "    acc_batches = 0\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    total_samples = 0\n",
    "    correct_val = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input_image, validation_image, label) in enumerate(val_loader):\n",
    "            \n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # Move inputs and labels to the GPU\n",
    "            output = siamese_net(input_image, validation_image)\n",
    "            loss = criterion(output, label)\n",
    "            result = round(output)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            total_samples += label.size(0)  # Increment total_samples by the batch size\n",
    "            val_correct += (result == label).sum().item()\n",
    "   \n",
    "            \n",
    "        avg_val_loss = val_loss / total_samples\n",
    "        \n",
    "        print(f\"Val Total Loss %f :\" %(val_loss))\n",
    "        print(f\"Val Average Loss %f :\" % (avg_val_loss))\n",
    "        print(f\"Val Accuracy %.2f :\" % (100 * (val_correct / total_samples ) ))\n",
    "        accuracies.append(100 * (val_correct / total_samples ))\n",
    "        losses.append(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac7af32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NEG_PATH = os.path.join(\"..\",\"test\",\"testing\",\"negetive\")\n",
    "TEST_POS_PATH = os.path.join(\"..\",\"test\",\"testing\",\"positive\")\n",
    "TEST_ANC_PATH = os.path.join(\"..\",\"test\",\"testing\",\"anchor\")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "postive = MergeImageDataset(TEST_ANC_PATH, TEST_POS_PATH, TEST_NEG_PATH, types = 1, transform = transform)\n",
    "negtive = MergeImageDataset(TEST_ANC_PATH, TEST_POS_PATH, TEST_NEG_PATH, types = 0, transform = transform)\n",
    "data = ConcatDataset([negtive,positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3faf7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_pos = DataLoader(postive)\n",
    "test_loader_neg = DataLoader(negtive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d22edaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0022]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[4.5994e-05]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0269]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[1.7364e-05]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0006]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[7.5005e-05]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0067]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0012]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.0002]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[1.0315e-05]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "---------------------NEGATIVES-----------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.9392]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[0.]]) with this outputtensor([[0.0060]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[0.]]) with this outputtensor([[0.1616]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[0.]]) with this outputtensor([[0.0007]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.9828]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.9172]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.9554]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.9811]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 1 and true is tensor([[0.]]) with this outputtensor([[0.5500]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[0.]]) with this outputtensor([[0.0736]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "Accuracy 20.00 :\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    val_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, (input_image, validation_image, label) in enumerate(test_loader_pos):\n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            output = siamese_net(input_image, validation_image)\n",
    "            result = 1 if output >= 0.5 else 0\n",
    "            val_correct += (result == label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "            print(f\"predicted {result} and true is {label} with this output{output}\")\n",
    "            print('-------------------------------------------')\n",
    "\n",
    "    print(\"---------------------NEGATIVES-----------------------------------------\")\n",
    "    for i, (input_image, validation_image, label) in enumerate(test_loader_neg):\n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            output = siamese_net(input_image, validation_image)\n",
    "            result = 1 if output >= 0.5 else 0\n",
    "            val_correct += (result == label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "            print(f\"predicted {result} and true is {label} with this output{output}\")\n",
    "            print('-------------------------------------------')\n",
    "            \n",
    "    print(f\"Accuracy %.2f :\" % (100 * (val_correct / total_samples) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce81a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
