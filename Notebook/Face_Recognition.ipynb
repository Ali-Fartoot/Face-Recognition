{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36df81d",
   "metadata": {},
   "source": [
    "# import files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3965f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from torch.utils.data import ConcatDataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch import flatten\n",
    "import torch.nn.functional as Fnn\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efab7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join(\"..\",'data','positive')\n",
    "NEG_PATH = os.path.join(\"..\",'data','negetive')\n",
    "ANC_PATH = os.path.join(\"..\",'data','anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a698db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76dec2f",
   "metadata": {},
   "source": [
    "# Untar Labelled Faces in the Wild Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1eed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95aae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir('lfw'):\n",
    "  for file in os.listdir(os.path.join('lfw',directory)):\n",
    "    EX_PATH = os.path.join('lfw',directory, file)\n",
    "    NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "    os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e415d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Collect anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe1340",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0416502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "def data_aug(img):\n",
    "    flag = [0,0,0,0]\n",
    "\n",
    "    data = []\n",
    "    while not all(x == 1 for x in flag):\n",
    "        if flag[0] == 0 and random.randint(0,100) / 100 < 0.5:\n",
    "            img = F.adjust_brightness(img, brightness_factor=1.1)\n",
    "            data.append(img)\n",
    "            flag[0] = 1\n",
    "        \n",
    "        if flag[1] == 0 and random.randint(0,100) / 100 < 0.5:\n",
    "            img = F.adjust_contrast(img, contrast_factor=torch.empty(1).uniform_(0.6, 1).item())\n",
    "            data.append(img)\n",
    "            flag[1] = 1\n",
    "            \n",
    "        if flag[2] == 0 and random.randint(0,100) / 100 < 0.5:\n",
    "            img = F.hflip(img)\n",
    "            data.append(img)\n",
    "            flag[2] = 1\n",
    "            \n",
    "        if flag[3] == 0 and random.randint(0,100) / 100 < 0.5:\n",
    "            img = F.adjust_saturation(img, saturation_factor=torch.empty(1).uniform_(0.9, 1).item())\n",
    "            data.append(img)\n",
    "            flag[3] = 1\n",
    "        \n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e371fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = F.to_tensor(img)\n",
    "    augmented_images = data_aug(img_tensor)\n",
    "    for i, image in enumerate(augmented_images):\n",
    "        image = F.to_pil_image(image)\n",
    "        image.save(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e67961",
   "metadata": {},
   "source": [
    "# Load Data in Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eb9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeImageDataset(Dataset):\n",
    "    def __init__(self,ANC_PATH  ,POS_PATH, NEG_PATH, types ,transform = None):\n",
    "        \n",
    "        self.POS_PATH = POS_PATH\n",
    "        self.NEG_PATH = NEG_PATH\n",
    "        self.ANC_PATH = ANC_PATH\n",
    "        \n",
    "        self.types = types\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.POS_IMG = os.listdir(POS_PATH)\n",
    "        self.NEG_IMG = os.listdir(NEG_PATH)\n",
    "        self.ANC_IMG = os.listdir(ANC_PATH)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ANC_IMG)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anc_dir  = os.path.join(self.ANC_PATH, self.ANC_IMG[idx])\n",
    "        anc_image = Image.open(anc_dir).convert('RGB')\n",
    "        \n",
    "        if self.types == 1: \n",
    "            pos_dir  = os.path.join(self.POS_PATH, self.POS_IMG[idx])\n",
    "            pos_image = Image.open(pos_dir).convert('RGB')\n",
    "\n",
    "        if self.types == 0: \n",
    "            neg_dir  = os.path.join(self.NEG_PATH, self.NEG_IMG[idx])\n",
    "            neg_image = Image.open(neg_dir).convert('RGB')\n",
    "        \n",
    "        data = [anc_image, pos_image if self.types == 1 else neg_image, torch.ones(1) if self.types == 1 else torch.zeros(1) ]\n",
    "\n",
    "        if self.transform:\n",
    "            data[0] = self.transform(data[0])\n",
    "            data[1] = self.transform(data[1])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27da1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(100),\n",
    "                                transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb4a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = MergeImageDataset(ANC_PATH, POS_PATH, NEG_PATH, types = 1, transform = transform)\n",
    "negtive = MergeImageDataset(ANC_PATH, POS_PATH, NEG_PATH, types = 0, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9698b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ConcatDataset([negtive,positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38ee98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the individual datasets into training and validation parts\n",
    "num_samples = len(data)\n",
    "indices = list(range(num_samples))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(0.2 * num_samples))  # Use 20% of data for validation\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Create samplers for the training and validation parts\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9fdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for the training and validation parts\n",
    "train_loader = DataLoader(data, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(data, batch_size=32, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb250620",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a422261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(Embedding, self).__init__()\n",
    "\n",
    "            self.conv_1 = nn.Conv2d(3, 64,kernel_size=(10, 10))\n",
    "            self.relu_1 = nn.ReLU()\n",
    "            self.maxpool_1 = nn.MaxPool2d(2, stride = 2 ,padding = 1)\n",
    "            \n",
    "            self.conv_2 =  nn.Conv2d(64, 128,kernel_size=(7, 7))\n",
    "            self.relu_2 =  nn.ReLU()\n",
    "            self.maxpool_2 = nn.MaxPool2d(2 , 2)\n",
    "            \n",
    "            self.conv_3 =  nn.Conv2d(128, 128,kernel_size=(4, 4))\n",
    "            self.relu_3 =  nn.ReLU()\n",
    "            self.maxpool_3 =  nn.MaxPool2d(2, 2, padding = 1)\n",
    "            \n",
    "            self.conv_4 =  nn.Conv2d(128, 256,kernel_size=(4, 4))\n",
    "            self.relu_4 =  nn.ReLU()\n",
    "            self.flatten = nn.Flatten(start_dim=1)\n",
    "            \n",
    "            self.linear = nn.Linear(256 * 6 * 6, 5000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.maxpool_3(x)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5084adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.embeder = Embedding()\n",
    "        self.classifier = nn.Linear(5000,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_image, validation_image):\n",
    "        input_image = self.embeder(input_image)\n",
    "        validation_image = self.embeder(validation_image)\n",
    "        result = torch.abs(input_image - validation_image)\n",
    "        x = self.classifier(result)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c911be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork()\n",
    "\n",
    "# Specify the input size\n",
    "input_size = (32, 3, 100, 100)\n",
    "\n",
    "# Move the model to the desired device (e.g., CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "x = torch.randn(input_size).to(device)\n",
    "y = torch.randn(input_size).to(device)\n",
    "test = model(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2f6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Val Total Loss 3.025530 :\n",
      "Val Average Loss 0.002573 :\n",
      "Epoch [2/10]\n",
      "Val Total Loss 0.194077 :\n",
      "Val Average Loss 0.000165 :\n",
      "Epoch [3/10]\n",
      "Val Total Loss 0.131449 :\n",
      "Val Average Loss 0.000112 :\n",
      "Epoch [4/10]\n",
      "Val Total Loss 0.542245 :\n",
      "Val Average Loss 0.000461 :\n",
      "Epoch [5/10]\n",
      "Val Total Loss 0.040660 :\n",
      "Val Average Loss 0.000035 :\n",
      "Epoch [6/10]\n",
      "Val Total Loss 0.040771 :\n",
      "Val Average Loss 0.000035 :\n",
      "Epoch [7/10]\n",
      "Val Total Loss 0.007611 :\n",
      "Val Average Loss 0.000006 :\n",
      "Epoch [8/10]\n",
      "Val Total Loss 0.036195 :\n",
      "Val Average Loss 0.000031 :\n",
      "Epoch [9/10]\n",
      "Val Total Loss 0.031115 :\n",
      "Val Average Loss 0.000026 :\n",
      "Epoch [10/10]\n",
      "Val Total Loss 0.021470 :\n",
      "Val Average Loss 0.000018 :\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create an instance of the SiameseNetwork\n",
    "siamese_net = SiameseNetwork().to(device)\n",
    "\n",
    "# Define the loss function (e.g., Binary Cross Entropy)\n",
    "criterion =  nn.BCELoss()\n",
    "\n",
    "# Define the optimizer (e.g., Stochastic Gradient Descent)\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    total_samples = 0\n",
    "    # Iterate over the training dataset\n",
    "    for i, (input_image, validation_image, label) in enumerate(train_loader):     \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        input_image = input_image.to(device)\n",
    "        validation_image = validation_image.to(device)\n",
    "        label = label.to(device)\n",
    "        # Forward pass\n",
    "        output = siamese_net(input_image, validation_image)\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the running loss\n",
    "        train_loss += loss.item()\n",
    "        total_samples += label.size(0)  # Increment total_samples by the batch size\n",
    "    \n",
    "    avg_train_loss = train_loss / total_samples\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    \n",
    "        # Evaluate the model on the validation set\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    total_samples = 0\n",
    "    correct_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input_image, validation_image, label) in enumerate(val_loader):\n",
    "            \n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # Move inputs and labels to the GPU\n",
    "            outputs = siamese_net(input_image, validation_image)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_val += (predicted == label).sum().item()   \n",
    "                \n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss += loss.item()\n",
    "            total_samples += label.size(0)  # Increment total_samples by the batch size\n",
    "        \n",
    "        avg_val_loss = val_loss / total_samples\n",
    "\n",
    "        print(f\"Val Total Loss %f :\" %(val_loss))\n",
    "        print(f\"Val Average Loss %f :\" % (avg_val_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bde41",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09ecccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NEG_PATH = os.path.join(\"..\",\"test\",\"NEG\")\n",
    "TEST_POS_PATH = os.path.join(\"..\",\"test\",\"POS\")\n",
    "TEST_ANC_PATH = os.path.join(\"..\",\"test\",\"ANC\")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "postive = MergeImageDataset(TEST_ANC_PATH, TEST_POS_PATH, TEST_NEG_PATH, types = 1, transform = transform)\n",
    "negtive = MergeImageDataset(TEST_ANC_PATH, TEST_POS_PATH, TEST_NEG_PATH, types = 0, transform = transform)\n",
    "data = ConcatDataset([negtive,positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5af361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_pos = DataLoader(postive)\n",
    "test_loader_neg = DataLoader(negtive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2572d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0 and true is tensor([[1.]]) with this outputtensor([[0.4994]], device='cuda:0')\n",
      "-------------------------------------------\n",
      "predicted 0 and true is tensor([[0.]]) with this outputtensor([[8.4042e-14]], device='cuda:0')\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (input_image, validation_image, label) in enumerate(test_loader_pos):\n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            output = siamese_net(input_image, validation_image)\n",
    "            result = 1 if output >= 0.5 else 0\n",
    "            print(f\"predicted {result} and true is {label} with this output{output}\")\n",
    "            print('-------------------------------------------')\n",
    "\n",
    "\n",
    "    for i, (input_image, validation_image, label) in enumerate(test_loader_neg):\n",
    "            input_image = input_image.to(device)\n",
    "            validation_image = validation_image.to(device)\n",
    "            output = siamese_net(input_image, validation_image)\n",
    "            result = 1 if output >= 0.5 else 0\n",
    "            print(f\"predicted {result} and true is {label} with this output{output}\")\n",
    "            print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e990e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(image):\n",
    "    image = np.squeeze(image) \n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    plt.figure(figsize=(10, 8)) \n",
    "    plt.imshow(image)  # Display the image using a grayscale colormap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5998f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
